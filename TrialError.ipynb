{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mann\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nhl_df=pd.read_csv(\"assets/nhl.csv\")\n",
    "cities=pd.read_html(\"assets/wikipedia_data.html\")[1]\n",
    "cities=cities.iloc[:-1,[0,3,5,6,7,8]]\n",
    "# YOUR CODE HERE\n",
    "nhl_df = nhl_df[nhl_df['year'] == 2018]\n",
    "cities = pd.read_html('assets/wikipedia_data.html')[1]\n",
    "#cities.rename({'Population (2016 est.)[8]': 'Population'}, axis=1, inplace=True)\n",
    "new_nhl = cities[['Metropolitan area', 'NHL']]\n",
    "new_nhl['LName'] = new_nhl['NHL'].apply(lambda x: re.findall('[A-Z][a-z]+', x))\n",
    "new_nhl = new_nhl.explode(column='LName').drop('NHL', axis=1).dropna()\n",
    "new_nhl.rename({'LName': 'team_LName'}, axis=1, inplace=True)\n",
    "nhlteams_index = new_nhl['Metropolitan area'].unique()\n",
    "nhl_df['team_LName'] = nhl_df['team'].apply(lambda x: re.findall('.+\\s(\\w+)\\*?', x)[-1])\n",
    "nhl_cities = nhl_df.merge(new_nhl, right_on='team_LName', left_on='team_LName')\n",
    "nhl_cities['W'] = nhl_cities['W'].astype(int)\n",
    "nhl_cities['L'] = nhl_cities['L'].astype(int)\n",
    "nhl_cities['W/L_%'] = nhl_cities['W'] / (nhl_cities['L'] + nhl_cities['W'])\n",
    "nhl_cities_merged = nhl_cities.groupby('Metropolitan area').agg({'W/L_%': 'mean'}).sort_index()\n",
    "q1 = nhl_cities_merged.merge(cities[['Metropolitan area', 'Population (2016 est.)[8]']], on='Metropolitan area')\n",
    "q1 = q1.set_index('Metropolitan area').loc[nhlteams_index]\n",
    "q1['Population (2016 est.)[8]'] = q1['Population (2016 est.)[8]'].astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W/L_%</th>\n",
       "      <th>Population (2016 est.)[8]</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metropolitan area</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>New York City</th>\n",
       "      <td>0.518201</td>\n",
       "      <td>20153634.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Los Angeles</th>\n",
       "      <td>0.622895</td>\n",
       "      <td>13310447.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>San Francisco Bay Area</th>\n",
       "      <td>0.625000</td>\n",
       "      <td>6657982.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chicago</th>\n",
       "      <td>0.458333</td>\n",
       "      <td>9512999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dallas–Fort Worth</th>\n",
       "      <td>0.567568</td>\n",
       "      <td>7233323.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Washington, D.C.</th>\n",
       "      <td>0.653333</td>\n",
       "      <td>6131977.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Philadelphia</th>\n",
       "      <td>0.617647</td>\n",
       "      <td>6070500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Boston</th>\n",
       "      <td>0.714286</td>\n",
       "      <td>4794447.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Minneapolis–Saint Paul</th>\n",
       "      <td>0.633803</td>\n",
       "      <td>3551036.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Denver</th>\n",
       "      <td>0.589041</td>\n",
       "      <td>2853077.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Miami–Fort Lauderdale</th>\n",
       "      <td>0.594595</td>\n",
       "      <td>6066387.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phoenix</th>\n",
       "      <td>0.414286</td>\n",
       "      <td>4661537.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Detroit</th>\n",
       "      <td>0.434783</td>\n",
       "      <td>4297617.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Toronto</th>\n",
       "      <td>0.653333</td>\n",
       "      <td>5928040.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tampa Bay Area</th>\n",
       "      <td>0.701299</td>\n",
       "      <td>3032171.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pittsburgh</th>\n",
       "      <td>0.618421</td>\n",
       "      <td>2342299.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>St. Louis</th>\n",
       "      <td>0.578947</td>\n",
       "      <td>2807002.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nashville</th>\n",
       "      <td>0.746479</td>\n",
       "      <td>1865298.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Buffalo</th>\n",
       "      <td>0.357143</td>\n",
       "      <td>1132804.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Montreal</th>\n",
       "      <td>0.420290</td>\n",
       "      <td>4098927.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vancouver</th>\n",
       "      <td>0.436620</td>\n",
       "      <td>2463431.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Columbus</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>2041520.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Calgary</th>\n",
       "      <td>0.513889</td>\n",
       "      <td>1392609.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ottawa</th>\n",
       "      <td>0.394366</td>\n",
       "      <td>1323783.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Edmonton</th>\n",
       "      <td>0.473684</td>\n",
       "      <td>1321426.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Winnipeg</th>\n",
       "      <td>0.722222</td>\n",
       "      <td>778489.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Las Vegas</th>\n",
       "      <td>0.680000</td>\n",
       "      <td>2155664.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Raleigh</th>\n",
       "      <td>0.507042</td>\n",
       "      <td>1302946.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           W/L_%  Population (2016 est.)[8]\n",
       "Metropolitan area                                          \n",
       "New York City           0.518201                 20153634.0\n",
       "Los Angeles             0.622895                 13310447.0\n",
       "San Francisco Bay Area  0.625000                  6657982.0\n",
       "Chicago                 0.458333                  9512999.0\n",
       "Dallas–Fort Worth       0.567568                  7233323.0\n",
       "Washington, D.C.        0.653333                  6131977.0\n",
       "Philadelphia            0.617647                  6070500.0\n",
       "Boston                  0.714286                  4794447.0\n",
       "Minneapolis–Saint Paul  0.633803                  3551036.0\n",
       "Denver                  0.589041                  2853077.0\n",
       "Miami–Fort Lauderdale   0.594595                  6066387.0\n",
       "Phoenix                 0.414286                  4661537.0\n",
       "Detroit                 0.434783                  4297617.0\n",
       "Toronto                 0.653333                  5928040.0\n",
       "Tampa Bay Area          0.701299                  3032171.0\n",
       "Pittsburgh              0.618421                  2342299.0\n",
       "St. Louis               0.578947                  2807002.0\n",
       "Nashville               0.746479                  1865298.0\n",
       "Buffalo                 0.357143                  1132804.0\n",
       "Montreal                0.420290                  4098927.0\n",
       "Vancouver               0.436620                  2463431.0\n",
       "Columbus                0.600000                  2041520.0\n",
       "Calgary                 0.513889                  1392609.0\n",
       "Ottawa                  0.394366                  1323783.0\n",
       "Edmonton                0.473684                  1321426.0\n",
       "Winnipeg                0.722222                   778489.0\n",
       "Las Vegas               0.680000                  2155664.0\n",
       "Raleigh                 0.507042                  1302946.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012486162921209909"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "population_by_region = q1['Population (2016 est.)[8]'] # pass in metropolitan area population from cities\n",
    "win_loss_by_region = q1['W/L_%'] # pass in win/loss ratio from nhl_df in the same order as cities[\"Metropolitan area\"]\n",
    "\n",
    "stats.pearsonr(population_by_region, win_loss_by_region)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15003737475409495"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import re\n",
    "\n",
    "def mlb_correlation(): \n",
    "    # YOUR CODE HERE\n",
    "        \n",
    "    mlb_df=pd.read_csv(\"assets/mlb.csv\")\n",
    "    cities_df=pd.read_html(\"assets/wikipedia_data.html\")[1]\n",
    "    cities_df=cities_df.iloc[:-1,[0,3,5,6,7,8]]\n",
    "    cities_df.rename({'Population (2016 est.)[8]': 'Population'}, axis=1, inplace=True)\n",
    "    \n",
    "    mlb_df = pd.read_csv('assets/mlb.csv')\n",
    "    mlb_df = mlb_df[mlb_df['year'] == 2018]\n",
    "    new_mlb = cities_df[['Metropolitan area', 'MLB']]\n",
    "    new_mlb.loc[:, 'team_LName'] = cities_df.loc[:, 'MLB'].apply(lambda x: re.findall('[A-Z][a-z]+\\s[A-Z][a-z]+|[A-Z][a-z]+', x))\n",
    "    new_mlb = new_mlb.explode(column='team_LName').dropna().drop('MLB', axis=1)\n",
    "    mlb_index = new_mlb['Metropolitan area'].unique()\n",
    "    mlb_df.loc[:, 'team_LName'] = mlb_df.loc[:, 'team'].apply(lambda x: re.findall('.+\\s([A-Z][a-z]+)', x)[0])\n",
    "    mlb_df.loc[0, 'team_LName'] = 'Red Sox'\n",
    "    mlb_df.loc[8, 'team_LName'] = 'White Sox'\n",
    "    mlb_df.loc[3, 'team_LName'] = 'Blue Jays'\n",
    "    q3 = new_mlb.merge(mlb_df, on='team_LName').groupby('Metropolitan area').agg({'W-L%': 'mean'}).loc[mlb_index]\n",
    "    q3 = q3.reset_index().merge(cities_df[['Metropolitan area', 'Population']], on='Metropolitan area').set_index('Metropolitan area')\n",
    "    q3['W-L%'] = q3['W-L%'].astype(np.float)\n",
    "    q3['Population'] = q3['Population'].astype(np.float)\n",
    "    \n",
    "    population_by_region = q3['Population'] # pass in metropolitan area population from cities\n",
    "    win_loss_by_region = q3['W-L%'] # pass in win/loss ratio from mlb_df in the same order as cities[\"Metropolitan area\"]\n",
    "\n",
    "    assert len(population_by_region) == len(win_loss_by_region), \"Q3: Your lists must be the same length\"\n",
    "    assert len(population_by_region) == 26, \"Q3: There should be 26 teams being analysed for MLB\"\n",
    "\n",
    "    return stats.pearsonr(population_by_region, win_loss_by_region)[0]\n",
    "\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "mlb_correlation()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mann\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\Mann\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Mann\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Mann\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NFL</th>\n",
       "      <th>NBA</th>\n",
       "      <th>NHL</th>\n",
       "      <th>MLB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NFL</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.937509</td>\n",
       "      <td>0.030318</td>\n",
       "      <td>0.803459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NBA</th>\n",
       "      <td>0.937509</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.022386</td>\n",
       "      <td>0.949566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NHL</th>\n",
       "      <td>0.030318</td>\n",
       "      <td>0.022386</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLB</th>\n",
       "      <td>0.803459</td>\n",
       "      <td>0.949566</td>\n",
       "      <td>0.000703</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          NFL       NBA       NHL       MLB\n",
       "NFL       NaN  0.937509  0.030318  0.803459\n",
       "NBA  0.937509       NaN  0.022386  0.949566\n",
       "NHL  0.030318  0.022386       NaN  0.000703\n",
       "MLB  0.803459  0.949566  0.000703       NaN"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def q5():\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import re\n",
    "    from scipy import stats\n",
    "    \n",
    "    cities_df = pd.read_html('assets/wikipedia_data.html')[1]\n",
    "    cities_df.rename({'Population (2016 est.)[8]': 'Population'}, axis=1, inplace=True)\n",
    "    cities_df = cities_df.iloc[:-1, :]\n",
    "    cities_df['Population'] = cities_df['Population'].astype(np.float)\n",
    "    \n",
    "    \n",
    "    nhl_df = pd.read_csv('assets/nhl.csv')\n",
    "    nhl_df = nhl_df[nhl_df['year'] == 2018]\n",
    "    metro_nhl = cities_df[['Metropolitan area', 'NHL']]\n",
    "    metro_nhl['team_LName'] = metro_nhl['NHL'].apply(lambda x: re.findall('[A-Z][a-z]+', x))\n",
    "    metro_nhl = metro_nhl.explode(column='team_LName').dropna()\n",
    "    metro_nhl.drop('NHL', axis=1, inplace=True)\n",
    "    nhl_index = metro_nhl['Metropolitan area'].unique()\n",
    "    nhl_df['team_LName'] = nhl_df['team'].apply(lambda x: re.findall('.+\\s([A-Z1-9]+[a-z]+)\\*?', x)[0])\n",
    "    merged_nhl = metro_nhl.merge(nhl_df, on='team_LName')\n",
    "    merged_nhl['W'] = merged_nhl['W'].astype(np.float)\n",
    "    merged_nhl['L'] = merged_nhl['L'].astype(np.float)\n",
    "    merged_nhl['W/L%'] = merged_nhl['W'] / (merged_nhl['W'] + merged_nhl['L'])\n",
    "    grouped_nhl = merged_nhl.groupby('Metropolitan area').agg({'W/L%': 'mean'}).merge(cities_df[['Metropolitan area', 'Population']], on='Metropolitan area')\n",
    "    grouped_nhl.set_index('Metropolitan area', inplace=True)\n",
    "    q1 = grouped_nhl.loc[nhl_index, :]\n",
    "    \n",
    "    \n",
    "    nba_df = pd.read_csv('assets/nba.csv')\n",
    "    nba_df = nba_df[nba_df['year'] == 2018]\n",
    "    nba_df['W/L%'] = nba_df['W/L%'].astype(np.float)\n",
    "    metro_nba = cities_df[['Metropolitan area', 'NBA']]\n",
    "    metro_nba['team_LName'] = metro_nba['NBA'].apply(lambda x: re.findall('[A-Z1-9]+[a-z]+', x))\n",
    "    metro_nba = metro_nba.explode(column='team_LName').dropna()\n",
    "    metro_nba.drop('NBA', axis=1, inplace=True)\n",
    "    nba_index = metro_nba['Metropolitan area'].unique()\n",
    "    nba_df['team_LName'] = nba_df['team'].apply(lambda x: re.findall('.*\\s([A-Z1-9]+[a-z]+)\\*?\\s\\S', x)[0])\n",
    "    merged_nba = nba_df.merge(metro_nba, on='team_LName')\n",
    "    grouped_nba = merged_nba.groupby(by='Metropolitan area').agg({'W/L%': 'mean'})\n",
    "    q2 = grouped_nba.reset_index().merge(cities_df[['Metropolitan area', 'Population']], on='Metropolitan area').set_index('Metropolitan area')\n",
    "    q2 = q2.loc[nba_index, :]\n",
    "    \n",
    "    \n",
    "    mlb_df = pd.read_csv('assets/mlb.csv')\n",
    "    mlb_df = mlb_df[mlb_df['year'] == 2018]\n",
    "    metro_mlb = cities_df[['Metropolitan area', 'MLB']]\n",
    "    metro_mlb['team_LName'] = metro_mlb['MLB'].apply(lambda x: re.findall('[A-Z][a-z]+\\s[A-Z][a-z]+|[A-Z1-9]+[a-z]+', x))\n",
    "    metro_mlb = metro_mlb.explode(column='team_LName').dropna().drop('MLB', axis=1)\n",
    "    mlb_index = metro_mlb['Metropolitan area'].unique()\n",
    "    mlb_df['team_LName'] = mlb_df['team'].apply(lambda x: re.findall('.+\\s([A-Z][a-z]+)', x)[0])\n",
    "    mlb_df.iloc[0, -1] = 'Red Sox'\n",
    "    mlb_df.iloc[8, -1] = 'White Sox'\n",
    "    mlb_df.iloc[3, -1] = 'Blue Jays'\n",
    "    merged_mlb = mlb_df.merge(metro_mlb, on='team_LName')\n",
    "    grouped_mlb = merged_mlb.groupby(by='Metropolitan area').agg({'W-L%': 'mean'})\n",
    "    q3 = grouped_mlb.reset_index().merge(cities_df[['Metropolitan area', 'Population']], on='Metropolitan area').set_index('Metropolitan area')\n",
    "    q3 = q3.loc[mlb_index, :]\n",
    "    \n",
    "    \n",
    "    nfl_df = pd.read_csv('assets/nfl.csv')\n",
    "    nfl_df = nfl_df[nfl_df['year'] == 2018]\n",
    "    nfl_df.drop([0, 5, 10, 15, 20, 25, 30, 35], axis=0, inplace=True)\n",
    "    nfl_df['W-L%'] = nfl_df['W-L%'].astype(np.float)\n",
    "    metro_nfl = cities_df[['Metropolitan area', 'NFL']]\n",
    "    metro_nfl['team_LName'] = metro_nfl['NFL'].apply(lambda x: re.findall('[A-Z1-9]+[a-z]+', x))\n",
    "    metro_nfl = metro_nfl.explode(column='team_LName').dropna().drop('NFL', axis=1)\n",
    "    nfl_index = metro_nfl['Metropolitan area'].unique()\n",
    "    nfl_df['team_LName'] = nfl_df['team'].apply(lambda x: re.findall('.*\\s([A-Z1-9]+[a-z]+)\\S*', x)[0])\n",
    "    merged_nfl = nfl_df.merge(metro_nfl, on='team_LName')\n",
    "    grouped_nfl = merged_nfl.groupby(by='Metropolitan area').agg({'W-L%': 'mean'})\n",
    "    q4 = grouped_nfl.reset_index().merge(cities_df[['Metropolitan area', 'Population']], on='Metropolitan area').set_index('Metropolitan area')\n",
    "    q4 = q4.loc[nfl_index, :]\n",
    "    \n",
    "    \n",
    "    sports = ['NFL', 'NBA', 'NHL', 'MLB']\n",
    "    p_values = pd.DataFrame({k:np.nan for k in sports}, index=sports)\n",
    "    \n",
    "    q1_nhl = q1.copy()\n",
    "    q2_nba = q2.copy()\n",
    "    q3_mlb = q3.copy()\n",
    "    q4_nfl = q4.copy()\n",
    "    \n",
    "    nfl_nba = pd.merge(q4_nfl, q2_nba, right_index=True, left_index=True)\n",
    "    p_values.loc['NFL', 'NBA'] = stats.ttest_rel(nfl_nba.iloc[:, 0], nfl_nba.iloc[:, 2])[1]\n",
    "    p_values.loc['NBA', 'NFL'] = p_values.loc['NFL', 'NBA']\n",
    "    \n",
    "    nfl_nhl = pd.merge(q1_nhl, q4_nfl, right_index=True, left_index=True)\n",
    "    p_values.loc['NHL', 'NFL'] = stats.ttest_rel(nfl_nhl.iloc[:, 0], nfl_nhl.iloc[:, 2])[1]\n",
    "    p_values.loc['NFL', 'NHL'] = p_values.loc['NHL', 'NFL']\n",
    "    \n",
    "    nfl_mlb = pd.merge(q3_mlb, q4_nfl, right_index=True, left_index=True)\n",
    "    p_values.loc['NFL', 'MLB'] = stats.ttest_rel(nfl_mlb.iloc[:, 0], nfl_mlb.iloc[:, 2])[1]\n",
    "    p_values.loc['MLB', 'NFL'] = p_values.loc['NFL', 'MLB']\n",
    "    \n",
    "    nba_nhl = pd.merge(q1_nhl, q2_nba, right_index=True, left_index=True)\n",
    "    p_values.loc['NBA', 'NHL'] = stats.ttest_rel(nba_nhl.iloc[:, 0], nba_nhl.iloc[:, 2])[1]\n",
    "    p_values.loc['NHL', 'NBA'] = p_values.loc['NBA', 'NHL']\n",
    "    \n",
    "    nba_mlb = pd.merge(q2_nba, q3_mlb, left_index=True, right_index=True)\n",
    "    p_values.loc['NBA', 'MLB'] = stats.ttest_rel(nba_mlb.iloc[:, 0], nba_mlb.iloc[:, 2])[1]\n",
    "    p_values.loc['MLB', 'NBA'] = p_values.loc['NBA', 'MLB']\n",
    "    \n",
    "    nhl_mlb = pd.merge(q1_nhl, q3_mlb, left_index=True, right_index=True)\n",
    "    p_values.loc['NHL', 'MLB'] = stats.ttest_rel(nhl_mlb.iloc[:, 0], nhl_mlb.iloc[:, 2])[1]\n",
    "    p_values.loc['MLB', 'NHL'] = p_values.loc['NHL', 'MLB']\n",
    "    \n",
    "    return p_values\n",
    "    \n",
    "    \n",
    "q5()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mann\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\Mann\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Mann\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Mann\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "p_values = q5()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_values.loc['NBA', 'NHL'] - 0.02 < 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
